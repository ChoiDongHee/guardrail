import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
from pykospacing import Spacing

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Dict, Optional
import logging
import uuid


from guardrail_cache_v2.services.mecapKoreanAnalyzer_service import RefinedKoreanPreprocessor
from guardrail_cache_v2.services.redis_service import EnhancedRedisManager
from guardrail_cache_v2.services.embedding_service import EmbeddingService


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Redis Vector Similarity Search API", version="1.0.0")


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ (CSS, JS)
if os.path.exists("static"):
    app.mount("/static", StaticFiles(directory="static"), name="static")

# -----------------------------
# âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
# -----------------------------
redis_client = EnhancedRedisManager()
SYNONYM_DICTS = redis_client.get_redis_json_key("SYNONYM_DICTS")
print("============================================================")
print(SYNONYM_DICTS)
print("============================================================")
processor = RefinedKoreanPreprocessor(synonym_dict=SYNONYM_DICTS)
rep_map = processor.build_synonym_map()
embedding_service = EmbeddingService.get_instance()


# -----------------------------
# âœ… Pydantic ëª¨ë¸
# -----------------------------
class QAItem(BaseModel):
    question: str
    method: Optional[str] = "vector"  # "vector" or "keyword"
    answer: str


class SearchQuery(BaseModel):
    query: str
    method: Optional[str] = "vector"  # ê¸°ë³¸ê°’: vector ("vector" or "keyword")


class SearchResponse(BaseModel):
    state: bool
    cached: bool
    similarity: float
    fresh_data: Optional[Dict] = None
    error: Optional[str] = None


class RegisterResponse(BaseModel):
    state: bool
    message: str
    id: Optional[str] = None
    error: Optional[str] = None


# -----------------------------
# âœ… HTML ë Œë”ë§ ë¼ìš°í„°
# -----------------------------
@app.get("/", response_class=HTMLResponse)
async def root():
    try:
        with open("templates/index.html", encoding="utf-8") as f:
            content = f.read()
            # í…œí”Œë¦¿ ë³€ìˆ˜ ì¹˜í™˜
            content = content.replace("{{ similarity_threshold }}", str(redis_client.similarity_threshold))
            return HTMLResponse(content=content)
    except Exception as e:
        logger.error("âŒ ë©”ì¸ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨", exc_info=e)
        raise HTTPException(status_code=500, detail="ë©”ì¸ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨")


@app.get("/admin", response_class=HTMLResponse)
async def get_admin():
    try:
        with open("templates/admin.html", encoding="utf-8") as f:
            content = f.read()
            return HTMLResponse(content=content)
    except Exception as e:
        logger.error("âŒ ê´€ë¦¬ì í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨", exc_info=e)
        raise HTTPException(status_code=500, detail="ê´€ë¦¬ì í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨")


# -----------------------------
# âœ… API ì—”ë“œí¬ì¸íŠ¸
# -----------------------------

@app.post("/api/query", response_model=SearchResponse)
async def search_question(search_query: SearchQuery):
    """
    ì§ˆë¬¸ ê²€ìƒ‰ API - ë‘ ê°€ì§€ ë°©ì‹ ì§€ì›
    - vector: ì „ì²´ ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰
    - keyword: MeCabìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ í›„ ê²€ìƒ‰
    """
    try:
        logger.info(f"ğŸ” ê²€ìƒ‰ ìš”ì²­: method={search_query.method}, query={search_query.query}")
        # # ê°€ì¥ ë¨¼ì €, ë‹¤ë¥¸ ì–´ë–¤ ì„í¬íŠ¸ë³´ë‹¤ë„ ë¨¼ì € í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        spacing = Spacing()
        search_query.query = spacing(search_query.query)
        logger.info(f"ğŸ”  ë„ì–´ì“°ê¸° ê²€ì‚¬ê¸°: method={search_query.method}, query={search_query.query}")

        if search_query.method == "keyword":
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            return await _search_by_keywords(search_query.query)
        else:
            # ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ (ê¸°ë³¸ê°’)
            return await _search_by_vector(search_query.query)

    except Exception as e:
        logger.error("âŒ ê²€ìƒ‰ ì‹¤íŒ¨", exc_info=e)
        return SearchResponse(
            state=False,
            cached=False,
            similarity=0.0,
            error=str(e)
        )


@app.post("/api/data", response_model=RegisterResponse)
async def register_question(qa: QAItem):
    """
    ì§ˆë¬¸-ë‹µë³€ ë“±ë¡ API
    - vector: ì§ˆë¬¸ ì „ì²´ë¥¼ ì„ë² ë”©
    - keyword: MeCab ì²˜ë¦¬ëœ í‚¤ì›Œë“œë¥¼ ì„ë² ë”©
    """
    try:
        logger.info(f"ğŸ“ ì§ˆë¬¸ ë“±ë¡: {qa.question[:50]}... (ë°©ì‹: {qa.method})")
        qa.question= qa.question.lower()
        keyword_str = ""
        question_embedding = None

        if qa.method == "keyword":
            # í‚¤ì›Œë“œ ê²€ìƒ‰ ëª¨ë“œ: MeCabìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ í›„ ì„ë² ë”©
            logger.info("ğŸ” í‚¤ì›Œë“œ ëª¨ë“œ: MeCab ì²˜ë¦¬ í›„ ì„ë² ë”©")

            # 1. í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ê·œí™”
            keywords = processor.extract_keywords(qa.question)
            normalized_keywords = processor.apply_synonym_replacement(keywords, rep_map)
            keyword_str = " ".join(normalized_keywords)

            logger.info(f"ğŸ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
            logger.info(f"ğŸ”„ ì •ê·œí™”ëœ í‚¤ì›Œë“œ: {normalized_keywords}")
            logger.info(f"ğŸ“„ í‚¤ì›Œë“œ ë¬¸ìì—´: '{keyword_str}'")

            qa.question = keyword_str
            # 2. í‚¤ì›Œë“œ ë¬¸ìì—´ì„ ì„ë² ë”©
            if keyword_str.strip():
                question_embedding = embedding_service.get_embedding(keyword_str)
            else:
                logger.warning("âš ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ì–´ì„œ ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ì„ë² ë”©")
                question_embedding = embedding_service.get_embedding(qa.question)
        else:
            # ë²¡í„° ê²€ìƒ‰ ëª¨ë“œ: ì§ˆë¬¸ ì „ì²´ë¥¼ ì„ë² ë”©
            logger.info("ğŸ¯ ë²¡í„° ëª¨ë“œ: ì§ˆë¬¸ ì „ì²´ ì„ë² ë”©")
            question_embedding = embedding_service.get_embedding(qa.question)

        if question_embedding is None:
            raise ValueError("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")

        # 3. Redisì— ì €ì¥
        success = redis_client.store_question_response(
            qa.question,
            qa.answer,
            question_embedding,
        )

        if success:
            logger.info(f"âœ… ì§ˆë¬¸ ì €ì¥ ì™„ë£Œ: id={success}")
            return RegisterResponse(
                state=True,
                message="ì§ˆë¬¸ ì €ì¥ ì™„ë£Œ",
                id=success
            )
        else:
            raise ValueError("Redis ì €ì¥ ì‹¤íŒ¨")

    except Exception as e:
        logger.error("âŒ ì§ˆë¬¸ ë“±ë¡ ì‹¤íŒ¨", exc_info=e)
        return RegisterResponse(
            state=False,
            message="ì§ˆë¬¸ ë“±ë¡ ì˜¤ë¥˜",
            error=str(e)
        )


@app.get("/api/data")
async def get_all_questions(
        limit: int = 10,
        offset: int = 0,
        sort_by: str = "created_at",
        sort_order: str = "DESC"
):
    """
    ì „ì²´ ì§ˆë¬¸ ëª©ë¡ ì¡°íšŒ API
    """
    try:
        # Redis Searchë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ë„¤ì´ì…˜ëœ ê²°ê³¼ ì¡°íšŒ
        redis_conn = redis_client._get_redis_connection()

        # ì •ë ¬ ë°©í–¥ ì²˜ë¦¬
        sort_direction = "ASC" if sort_order.upper() == "ASC" else "DESC"

        # Redis ìŠ¤í‚¤ë§ˆì—ì„œ use_morphology í•„ë“œëŠ” ì¸ë±ì‹±í•˜ì§€ ì•ŠìŒ
        # ë‹¨ìˆœ ì €ì¥ìš© í•„ë“œë¡œë§Œ ì‚¬ìš©
        results = redis_conn.execute_command(
            "FT.SEARCH", redis_client.index_name, "*",
            "SORTBY", sort_by, sort_direction,
            "RETURN", 8, "question", "response", "category", "created_at", "last_accessed", "hits", "date_str",
            "use_morphology",
            "LIMIT", offset, limit
        )

        total_count = results[0] if results else 0
        entries = []

        # ê²°ê³¼ íŒŒì‹±
        for i in range(1, len(results), 2):
            if i + 1 < len(results):
                key = results[i]
                data = results[i + 1]

                # ë°ì´í„° íŒŒì‹±
                data_iter = iter(data)
                entry_dict = {}
                for k, v in zip(data_iter, data_iter):
                    entry_dict[k] = v

                entry = {
                    "id": key.replace(redis_client.key_prefix, ''),
                    "question": entry_dict.get('question', ''),
                    "response": entry_dict.get('response', ''),
                    "method": entry_dict.get('method', 'vector'),
                    "created_at": int(entry_dict.get('created_at', 0)),
                    "last_accessed": int(entry_dict.get('last_accessed', 0)),
                    "hits": int(entry_dict.get('hits', 0)),
                    "date_str": entry_dict.get('date_str', '')
                }
                entries.append(entry)

        return {
            "state": True,
            "entries": entries,
            "total": total_count,
            "limit": limit,
            "offset": offset
        }

    except Exception as e:
        logger.error("âŒ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨", exc_info=e)
        return {"state": False, "error": str(e)}


@app.delete("/api/data")
async def delete_question(delete_request: Dict[str, str]):
    """
    ì§ˆë¬¸ ì‚­ì œ API
    """
    try:
        question_id = delete_request.get("id")
        if not question_id:
            raise ValueError("IDê°€ í•„ìš”í•©ë‹ˆë‹¤")

        success = redis_client.delete_entry(question_id)

        if success:
            return {"state": True, "message": "ì‚­ì œ ì™„ë£Œ"}
        else:
            return {"state": False, "error": "ì‚­ì œí•  í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    except Exception as e:
        logger.error("âŒ ì‚­ì œ ì‹¤íŒ¨", exc_info=e)
        return {"state": False, "error": str(e)}


@app.get("/api/stats")
async def get_cache_stats():
    """
    ìºì‹œ í†µê³„ API
    """
    try:
        stats = redis_client.get_cache_stats()
        return {"state": True, "stats": stats}
    except Exception as e:
        logger.error("âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨", exc_info=e)
        return {"state": False, "error": str(e)}


# -----------------------------
# âœ… ë‚´ë¶€ ê²€ìƒ‰ í•¨ìˆ˜ë“¤
# -----------------------------

async def _search_by_vector(query: str) -> SearchResponse:
    """ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ - ì§ˆë¬¸ ì „ì²´ë¥¼ ì„ë² ë”©"""
    try:
        logger.info(f"ğŸ” ë²¡í„° ê²€ìƒ‰: ì§ˆë¬¸ ì „ì²´ ì„ë² ë”© - '{query}'")

        # ì§ˆë¬¸ ì „ì²´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        query_embedding = embedding_service.get_embedding(query)
        if query_embedding is None:
            raise ValueError("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")

        # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
        result = redis_client.search_similar_question(query_embedding)

        if result["is_cache"] and result["data"]:
            logger.info(f"âœ… ë²¡í„° ê²€ìƒ‰ ìºì‹œ íˆíŠ¸: ìœ ì‚¬ë„ {result['similarity']:.4f}")
            return SearchResponse(
                state=True,
                cached=True,
                similarity=result["similarity"],
                fresh_data={
                    "id": result["data"]["id"],
                    "question": result["data"]["question"],
                    "response": result["data"]["response"],
                    "hits": result["data"]["hits"],
                    "last_accessed": result["data"]["last_accessed"],
                    "created_at": result["data"]["created_at"]
                }
            )
        else:
            logger.info(f"âŒ ë²¡í„° ê²€ìƒ‰ ìºì‹œ ë¯¸ìŠ¤: ìœ ì‚¬ë„ {result['similarity']:.4f}")
            return SearchResponse(
                state=True,
                cached=False,
                similarity=result["similarity"]
            )

    except Exception as e:
        logger.error(f"ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        raise


async def _search_by_keywords(query: str) -> SearchResponse:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ - MeCab ì²˜ë¦¬ëœ í‚¤ì›Œë“œë¥¼ ì„ë² ë”©"""
    try:

        logger.info(f"ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰: MeCab ì²˜ë¦¬ í›„ ì„ë² ë”© - '{query}'")

        # 1. MeCabìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ê·œí™”
        synonym = processor.apply_synonym_replacement(query, rep_map)
        keywords = processor.extract_keywords(query)
        normalized = processor.apply_synonym_replacement(keywords, rep_map)
        keyword_string = " ".join(normalized)

        logger.info(f"ğŸ“ ì›ë³¸ : {query}")
        logger.info(f"ğŸ“ ë™ì˜ì–´  : {synonym}")
        logger.info(f"ğŸ”„ ì •ê·œí™”ëœ í‚¤ì›Œë“œ: {normalized}")
        logger.info(f"ğŸ“„ í‚¤ì›Œë“œ ë¬¸ìì—´: '{keyword_string}'")

        if not keyword_string.strip():
            logger.warning("âš ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return SearchResponse(
                state=True,
                cached=False,
                similarity=0.0
            )

        # 2. í‚¤ì›Œë“œ ë¬¸ìì—´ì„ ë²¡í„°ë¡œ ë³€í™˜
        keyword_embedding = embedding_service.get_embedding(keyword_string)
        if keyword_embedding is None:
            raise ValueError("í‚¤ì›Œë“œ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")

        # 3. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
        result = redis_client.search_similar_question(keyword_embedding)

        if result["is_cache"] and result["data"]:
            logger.info(f"âœ… í‚¤ì›Œë“œ ê²€ìƒ‰ ìºì‹œ íˆíŠ¸: ìœ ì‚¬ë„ {result['similarity']:.4f}")
            return SearchResponse(
                state=True,
                cached=True,
                similarity=result["similarity"],
                fresh_data={
                    "id": result["data"]["id"],
                    "question": result["data"]["question"],
                    "response": result["data"]["response"],
                    "hits": result["data"]["hits"],
                    "last_accessed": result["data"]["last_accessed"],
                    "created_at": result["data"]["created_at"]
                }
            )
        else:
            logger.info(f"âŒ í‚¤ì›Œë“œ ê²€ìƒ‰ ìºì‹œ ë¯¸ìŠ¤: ìœ ì‚¬ë„ {result['similarity']:.4f}")
            return SearchResponse(
                state=True,
                cached=False,
                similarity=result["similarity"]
            )

    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        raise


# -----------------------------
# âœ… ë ˆê±°ì‹œ ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ í˜¸í™˜ì„±)
# -----------------------------

@app.post("/register")
async def legacy_register(qa: QAItem):
    """ë ˆê±°ì‹œ ë“±ë¡ ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    result = await register_question(qa)
    if result.state:
        return {"message": result.message, "id": result.id}
    else:
        raise HTTPException(status_code=500, detail=result.error)





@app.get("/cache_update/")
async def cache_update():
    try:
        synonym_dicts = redis_client.get_redis_json_key("SYNONYM_DICTS")
        print("cache_update============================================================")
        print(synonym_dicts)
        print("cache_update============================================================")
        processor.update_synonym_dict(synonym_dicts)
        return {
            "status": "cache_update",
            "redis": "connected",
            "data": synonym_dicts
        }
    except:
        raise HTTPException(status_code=500)



# -----------------------------
# âœ… í—¬ìŠ¤ì²´í¬
# -----------------------------

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # Redis ì—°ê²° í™•ì¸
        redis_conn = redis_client._get_redis_connection()
        redis_conn.ping()

        return {
            "status": "healthy",
            "redis": "connected",
            "embedding_service": "ready",
            "mecab_processor": "ready"
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)