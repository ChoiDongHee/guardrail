import pandas as pd
import re
import time
from guardrail_cache_v2.services.redis_service import QuestionAnswerCacheService
from guardrail_cache_v2.services.mecapKoreanAnalyzer_service import RefinedKoreanPreprocessor
from guardrail_cache_v2.services.redis_service import EnhancedRedisManager, EmbeddingService


def extract_qa_from_block(text: str):
    """
    í•˜ë‚˜ì˜ ë¸”ë¡ì—ì„œ 'ì§ˆë¬¸:'ê³¼ 'ë‹µë³€:'ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    if not isinstance(text, str):
        return None, None

    # í° ë”°ì˜´í‘œ ì œê±° ë° ì–‘ìª½ ê³µë°± ì œê±°
    text = text.strip().strip('"').strip()

    # ì¤„ë°”ê¿ˆ í†µí•© í›„ ì¶”ì¶œ
    pattern = r"ì§ˆë¬¸:\s*(.*?)\s*ë‹µë³€:\s*(.*)"
    match = re.match(pattern, text, re.DOTALL)
    if match:
        question = match.group(1).strip()
        answer = match.group(2).strip()
        return question, answer
    return None, None


def bulk_insert_from_blocks(csv_path: str, similarity_threshold: float = 0.94):
    df = pd.read_csv(csv_path, header=None)  # í—¤ë” ì—†ìŒìœ¼ë¡œ ê°€ì •
    print(f"\nğŸ“¥ [íŒŒì¼ ì½ê¸° ì™„ë£Œ] '{csv_path}'ì—ì„œ {len(df)}ê°œì˜ Q&A ì¶”ì¶œ ì‹œë„\n")

    success, skipped, fail = 0, 0, 0

    for idx, row in df.iterrows():
        text = row[0]
        question, answer = extract_qa_from_block(text)

        if not question or not answer:
            print(f"âš ï¸ [{idx+1}] Q/A íŒŒì‹± ì‹¤íŒ¨ â†’ {text[:50]}...")
            fail += 1
            continue

        # 1. í‚¤ì›Œë“œ ì „ì²˜ë¦¬ ë° ì •ê·œí™”
        keywords = processor.extract_keywords(question)
        normalized_keywords = processor.apply_synonym_replacement(keywords, rep_map)
        keyword_str = " ".join(normalized_keywords).lower()

        if not keyword_str.strip():
            print(f"âš ï¸ [{idx+1}] í‚¤ì›Œë“œ ì—†ìŒ â†’ '{question[:30]}...' â†’ ìƒëµ")
            fail += 1
            continue

        print(f"\n[{idx+1}] ğŸ“„ ì§ˆë¬¸ í‚¤ì›Œë“œ: '{keyword_str}'")

        # 2. ì„ë² ë”© ìƒì„±
        embedding = embedding_service.get_embedding(keyword_str)
        if embedding is None:
            print(f"âŒ [{idx+1}] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
            fail += 1
            continue

        # 3. ìœ ì‚¬ë„ ê²€ì‚¬
        result = redis_client.search_similar_question(embedding, limit=1)
        similarity = result.get("similarity", 0.0)
        print(f"ğŸ” ìœ ì‚¬ë„ ê²€ì‚¬: {similarity:.4f}")

        if similarity >= similarity_threshold:
            print(f"â›” ìœ ì‚¬ë„ {similarity:.4f} â‰¥ {similarity_threshold} â†’ ì €ì¥ ìƒëµ")
            skipped += 1
            continue

        # 4. ì €ì¥
        redis_client.store_question_response(keyword_str, answer, embedding)
        print(f"âœ… ì €ì¥ ì™„ë£Œ")
        success += 1

        time.sleep(0.01)

    print("\nğŸ“Š [ìš”ì•½ ê²°ê³¼]")
    print(f"   - ì €ì¥ ì„±ê³µ: {success}")
    print(f"   - ìœ ì‚¬ë„ ì´ˆê³¼ë¡œ ê±´ë„ˆëœ€: {skipped}")
    print(f"   - ì‹¤íŒ¨ (íŒŒì‹±/ì„ë² ë”© ë“±): {fail}")


if __name__ == "__main__":
    # -----------------------------
    # âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    # -----------------------------
    redis_client = EnhancedRedisManager()
    processor = RefinedKoreanPreprocessor()
    rep_map = processor.build_synonym_map()
    embedding_service = EmbeddingService.get_instance()

    # -----------------------------
    # ğŸ”„ ì¸ì„œíŠ¸ ì‹¤í–‰
    # -----------------------------
    bulk_insert_from_blocks("í‡´ì§ì—°ê¸ˆ_ìì£¼ë¬»ëŠ”ì§ˆë¬¸_QA.csv")
    bulk_insert_from_blocks("í‡´ì§ì—°ê¸ˆ_ì‹œë‚˜ë¦¬ì˜¤_200.csv")
