# -----------------------------
# ğŸ“ mecabKoreanAnalyzer_service.py (ì‹±ê¸€í„´ ì ìš© + ë¡œê¹… ì •ë¹„ + ì£¼ì„ ë³´ì™„ + í‚¤ì›Œë“œì¶”ì¶œ ë¡œì§ ê°œì„ )
# -----------------------------
import os
import re
import json
import logging
from typing import List, Dict, Tuple, Optional
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def build_stopwords_set(dicts: List[Dict]) -> set:
    """í™˜ê²½ ë³€ìˆ˜ì— ì •ì˜ëœ ë¶ˆìš©ì–´ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¶ˆìš©ì–´ ë‹¨ì–´ë§Œ ì¶”ì¶œí•˜ì—¬ ì§‘í•©ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    stopwords = set()
    for group in dicts:
        stopwords.update(group["words"])
    return stopwords


class RefinedKoreanPreprocessor:
    """
    í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì „ì²˜ë¦¬ê¸° í´ë˜ìŠ¤ (ì‹±ê¸€í„´)
    - ë™ì˜ì–´ ì‚¬ì „ ê´€ë¦¬
    - ë¶ˆìš©ì–´ ì²˜ë¦¬
    - í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    """

    _instance = None

    @classmethod
    def get_instance(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = cls(*args, **kwargs)
        return cls._instance

    def __init__(self, synonym_dict: Optional[List[Dict[str, List[str]]]] = None,
                 stopwords: Optional[List[str]] = None,
                 meaningful_pos: Optional[List[str]] = None):
        if hasattr(self, '_initialized') and self._initialized:
            return

        self.logger = logging.getLogger(self.__class__.__name__)

        try:
            import MeCab
            self.tagger = MeCab.Tagger()
            self.logger.info("âœ… MeCab ë¶„ì„ê¸° ë¡œë”© ì™„ë£Œ")
        except ImportError:
            try:
                import mecab_ko as MeCab
                self.tagger = MeCab.Tagger()
                self.logger.info("âœ… mecab_ko ëŒ€ì²´ ë¡œë”© ì™„ë£Œ")
            except ImportError as e:
                self.logger.exception("âŒ MeCab ë¶„ì„ê¸° ë¡œë”© ì‹¤íŒ¨")
                raise ImportError("mecab-ko ì„¤ì¹˜ í•„ìš”: pip install mecab-ko") from e

        self._synonym_dict = synonym_dict if synonym_dict else []
        self._stopwords = set(stopwords) if stopwords else build_stopwords_set(json.loads(os.getenv("STOPWORDS_DICTS", "[]")))
        self._meaningful_pos = set(meaningful_pos if meaningful_pos else ['NNG', 'NNP', 'NNB', 'VV', 'VA', 'MM', 'MAG', 'SL', 'SN', 'SH'])
        self._initialized = True

    def update_synonym_dict(self, synonym_dicts_json: str) -> bool:
        """JSON ë¬¸ìì—´ ë˜ëŠ” ê°ì²´ë¡œë¶€í„° ë™ì˜ì–´ ì‚¬ì „ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            self.logger.info("ğŸ”„ ë™ì˜ì–´ ì‚¬ì „ ì—…ë°ì´íŠ¸ ì‹œì‘")
            data = json.loads(synonym_dicts_json) if isinstance(synonym_dicts_json, str) else synonym_dicts_json
            if not isinstance(data, list):
                raise ValueError("ë™ì˜ì–´ ë°ì´í„°ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤")

            for entry in data:
                if not isinstance(entry, dict) or "representative" not in entry or "synonyms" not in entry:
                    raise ValueError("ê° í•­ëª©ì€ 'representative'ì™€ 'synonyms' í‚¤ í¬í•¨ í•„ìš”")

            self._synonym_dict = data
            self.logger.info(f"âœ… ë™ì˜ì–´ ì‚¬ì „ ì—…ë°ì´íŠ¸ ì™„ë£Œ - {len(self._synonym_dict)}ê°œ ê·¸ë£¹")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ë™ì˜ì–´ ì‚¬ì „ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
            return False

    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤."""
        try:
            return re.sub(r'\s+', ' ', text.strip())
        except Exception as e:
            self.logger.error(f"âŒ í…ìŠ¤íŠ¸ ì •ì œ ì‹¤íŒ¨: {e}", exc_info=True)
            return text

    def parse_mecab(self, text: str) -> List[Tuple[str, str]]:
        """
        í…ìŠ¤íŠ¸ë¥¼ MeCab í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ í†µí•´ (ì–´ê°„/í‘œì œì–´, í’ˆì‚¬) ìŒì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        - lemma: í˜•íƒœì†Œì˜ ì›í˜• ë˜ëŠ” í‘œì œì–´
        - pos: í’ˆì‚¬ íƒœê·¸ (ì˜ˆ: NNG, NNP ë“±)
        """
        try:
            result = self.tagger.parse(text)
            morphemes = []
            for line in result.split('\n'):
                if line == 'EOS' or not line:
                    continue
                parts = line.split('\t')
                if len(parts) >= 2:
                    morpheme = parts[0]
                    feature = parts[1].split(',')
                    pos = feature[0]
                    lemma = feature[6] if len(feature) > 6 and feature[6] != '*' else morpheme
                    morphemes.append((lemma, pos))
            return morphemes
        except Exception as e:
            self.logger.exception(f"âŒ í˜•íƒœì†Œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    def extract_keywords(self, text: str) -> List[str]:
        """ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ ë°©ì‹: í˜•íƒœì†Œ ë¶„ì„ í›„ ë¶ˆìš©ì–´ ì œê±° ë° ë™ì˜ì–´ ì •ë¦¬"""
        try:
            self.logger.info("ğŸš€ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘ (ê¸°ë³¸ ë°©ì‹)")
            return self.extract_keywords_with_synonym(text)
        except Exception as e:
            self.logger.error(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
            return []

    def extract_keywords_with_synonym(self, text: str) -> List[str]:
        """
        ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ: ë™ì˜ì–´ ì •ë¦¬ â†’ í˜•íƒœì†Œ ë¶„ì„ â†’ ë¶ˆìš©ì–´ ì œê±° â†’ ë™ì˜ì–´ ì¬ì ìš©
        ì´ì¤‘ ë™ì˜ì–´ ë§¤í•‘ êµ¬ì¡°ë¡œ ì˜ë¯¸ ì •ì œë¥¼ ê°•í™”í•©ë‹ˆë‹¤.
        """
        try:
            self.logger.info("ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘ (ë™ì˜ì–´-í˜•íƒœì†Œ-ë™ì˜ì–´ ë°©ì‹)")
            rep_map = self.build_synonym_map()
            text_synonym_applied = ' '.join(rep_map.get(word, word) for word in text.split())

            morphemes = self.parse_mecab(self.clean_text(text_synonym_applied))
            keywords = [word for word, pos in morphemes
                        if pos in self._meaningful_pos and word not in self._stopwords and len(word) >= 2 and not re.match(r'^[a-zA-Z]$', word)]

            # ìµœì¢… ë™ì˜ì–´ ë§¤í•‘ ì ìš©
            normalized = [rep_map.get(word, word) for word in keywords]
            self.logger.info(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: {normalized}")
            return normalized
        except Exception as e:
            self.logger.error(f"âŒ ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
            return []

    def build_synonym_map(self) -> Dict[str, str]:
        """ë™ì˜ì–´ ì‚¬ì „ì—ì„œ {ë™ì˜ì–´: ëŒ€í‘œì–´} í˜•íƒœì˜ ì¹˜í™˜ ë§µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            rep_map = {}
            for entry in self._synonym_dict:
                rep = entry.get("representative")
                for word in entry.get("synonyms", []):
                    rep_map[word] = rep
            return rep_map
        except Exception as e:
            self.logger.error(f"âŒ ë™ì˜ì–´ ë§µ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return {}

    def apply_synonym_replacement(self, keywords: List[str]) -> List[str]:
        """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ë™ì˜ì–´ë¥¼ ëŒ€í‘œì–´ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤."""
        try:
            rep_map = self.build_synonym_map()
            return [rep_map.get(word, word) for word in keywords]
        except Exception as e:
            self.logger.error(f"âŒ ë™ì˜ì–´ ì •ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
            return keywords

    def join_keywords(self, keywords: List[str]) -> str:
        """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê³µë°±ìœ¼ë¡œ ì—°ê²°ëœ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            return ' '.join(keywords)
        except Exception as e:
            self.logger.error(f"âŒ í‚¤ì›Œë“œ ë¬¸ìì—´ ë³€í™˜ ì‹¤íŒ¨: {e}", exc_info=True)
            return ''

    # --- Getter / Setter ---

    @property
    def synonym_dict(self):
        return self._synonym_dict

    @synonym_dict.setter
    def synonym_dict(self, new_dict):
        if isinstance(new_dict, list):
            self._synonym_dict = new_dict

    @property
    def stopwords(self):
        return self._stopwords

    @stopwords.setter
    def stopwords(self, new_stopwords):
        if isinstance(new_stopwords, (set, list)):
            self._stopwords = set(new_stopwords)

    @property
    def meaningful_pos(self):
        return self._meaningful_pos

    @meaningful_pos.setter
    def meaningful_pos(self, new_pos):
        if isinstance(new_pos, (set, list)):
            self._meaningful_pos = set(new_pos)
