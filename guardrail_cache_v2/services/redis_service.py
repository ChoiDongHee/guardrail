# ===================================================================
# íŒŒì¼: enhanced_redis_util.py
# ì„¤ëª…: í–¥ìƒëœ Redis ê²€ìƒ‰ ë° ìºì‹± ì‹œìŠ¤í…œ
# ===================================================================

import os
import logging
import time
import json
import numpy as np
from datetime import datetime
from redis import ConnectionPool, Redis
from redis.exceptions import ResponseError, RedisError
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv
load_dotenv(override=True)  # ê°•ì œ ì¬ë¡œë“œ


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class EnhancedRedisManager:
    """í–¥ìƒëœ Redis ì—°ê²° ë° ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•œ ì‹±ê¸€í„´ í´ë˜ìŠ¤"""
    _instance = None

    @classmethod
    def get_instance(cls):
        """ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def __init__(self):
        """
        ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ì„ ë•Œë§Œ ì‹¤í–‰ë˜ëŠ” ì´ˆê¸°í™” ë©”ì„œë“œ.
        Redis ì—°ê²° í’€ì„ ìƒì„±í•˜ê³  ì¸ë±ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        """
        # ì‹±ê¸€í„´ íŒ¨í„´: __init__ì´ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œë˜ëŠ” ê²ƒì„ ë°©ì§€
        if hasattr(self, '_initialized'):
            return
        self._initialized = True

        logger.info("EnhancedRedisManager ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")

        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ Redis ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        self.host = os.getenv("REDIS_HOST", "localhost")
        self.port = int(os.getenv("REDIS_PORT", 6379))
        self.db = int(os.getenv("REDIS_DB", 0))
        self.password = os.getenv("REDIS_PASSWORD", None)

        # ì—°ê²° í’€ ìƒì„± (ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ì²´ì—ì„œ ê³µìœ )
        self.pool = ConnectionPool(
            host=self.host,
            port=self.port,
            db=self.db,
            password=self.password,
            decode_responses=True  # ìë™ UTF-8 ë””ì½”ë”© í™œì„±í™”
        )

        # ì„¤ì •ê°’ ì´ˆê¸°í™”
        self.index_name = os.getenv("REDIS_INDEX_NAME", "chat_admin_idx")
        self.key_prefix = os.getenv("REDIS_KEY_PREFIX", "chat_data:")
        self.vector_dim = int(os.getenv("VECTOR_DIM", 768))
        self.similarity_threshold = float(os.getenv("VECTOR_SIMILARITY_THRESHOLD", 0.95))

        # ì¸ë±ìŠ¤ ìƒì„± í™•ì¸
        self._ensure_index_exists()

    def _get_redis_connection(self) -> Redis:
        """ì—°ê²° í’€ì—ì„œ Redis ì—°ê²°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. (ìë™ ë””ì½”ë”© í™œì„±í™”)"""
        return Redis(connection_pool=self.pool)

    def _get_raw_redis_connection(self) -> Redis:
        """ì—°ê²° í’€ì—ì„œ ì›ì‹œ(bytes) Redis ì—°ê²°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. (ë²¡í„° ë°ì´í„°ìš©)"""
        return Redis(connection_pool=self.pool, decode_responses=False)

    def _ensure_index_exists(self) -> bool:
        """ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            redis_conn = self._get_redis_connection()

            # ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if self._index_exists():
                logger.info(f"ì¸ë±ìŠ¤ '{self.index_name}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                return True

            # ì¸ë±ìŠ¤ ìƒì„±
            return self._create_search_index()

        except Exception as e:
            logger.error(f"ì¸ë±ìŠ¤ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def _index_exists(self) -> bool:
        """ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            redis_conn = self._get_redis_connection()
            # FT.INFO ëª…ë ¹ìœ¼ë¡œ ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            redis_conn.execute_command("FT.INFO", self.index_name)
            return True
        except ResponseError:
            # ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ResponseError ë°œìƒ
            return False
        except Exception as e:
            logger.error(f"ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def _create_search_index(self) -> bool:
        """í–¥ìƒëœ ê²€ìƒ‰ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            redis_conn = self._get_redis_connection()

            # í–¥ìƒëœ ìŠ¤í‚¤ë§ˆ ì •ì˜
            schema = [
                # ë²¡í„° ê²€ìƒ‰ í•„ë“œ
                'question_vector', 'VECTOR', 'HNSW', '6',
                'TYPE', 'FLOAT32',
                'DIM', str(self.vector_dim),
                'DISTANCE_METRIC', 'COSINE',

                # í…ìŠ¤íŠ¸ ê²€ìƒ‰ í•„ë“œ
                'question', 'TEXT', 'SORTABLE',
                'response', 'TEXT',

                # ìˆ˜ì¹˜ ë° ì •ë ¬ í•„ë“œ
                'created_at', 'NUMERIC', 'SORTABLE',
                'last_accessed', 'NUMERIC', 'SORTABLE',
                'hits', 'NUMERIC', 'SORTABLE',

                # ë‚ ì§œ íƒœê·¸ í•„ë“œ (YYYYMMDD í˜•ì‹)
                'date_str', 'TAG', 'SORTABLE'
            ]

            cmd = [
                'FT.CREATE', self.index_name,
                'ON', 'HASH',
                'PREFIX', '1', self.key_prefix,
                'SCHEMA', *schema
            ]

            redis_conn.execute_command(*cmd)
            logger.info(f"ì¸ë±ìŠ¤ '{self.index_name}'ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            return True

        except ResponseError as e:
            if "Index already exists" in str(e):
                logger.info(f"ì¸ë±ìŠ¤ '{self.index_name}'ëŠ” ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                return True
            else:
                logger.error(f"ì¸ë±ìŠ¤ ìƒì„± ì¤‘ Redis ì˜¤ë¥˜: {e}")
                return False
        except Exception as e:
            logger.error(f"ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False

    # --- ë²¡í„° ê²€ìƒ‰ ê´€ë ¨ í—¬í¼ í•¨ìˆ˜ë“¤ ---

    def _prepare_vector_bytes(self, vector) -> Optional[bytes]:
        """ì…ë ¥ ë²¡í„°ë¥¼ ê²€ì¦í•˜ê³  Redisê°€ ìš”êµ¬í•˜ëŠ” bytes í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            if isinstance(vector, bytes):
                return vector
            if hasattr(vector, 'shape') or isinstance(vector, (list, tuple)):
                return np.array(vector, dtype=np.float32).tobytes()

            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë²¡í„° íƒ€ì…ì…ë‹ˆë‹¤: {type(vector)}")
            return None
        except Exception as e:
            logger.error(f"ë²¡í„° ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def _build_vector_search_query(self, vector_bytes: bytes, limit: int = 5) -> List:
        """ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        return [
            "FT.SEARCH", self.index_name,
            f"*=>[KNN {limit} @question_vector $BLOB]",
            "PARAMS", 2, "BLOB", vector_bytes,
            "RETURN", 7, "question", "response", "created_at", "last_accessed", "hits", "date_str",
            "__question_vector_score",
            "SORTBY", "__question_vector_score", "ASC",  # ê±°ë¦¬ìˆœ ì •ë ¬ ì¶”ê°€
            "LIMIT", 0, limit,
            "DIALECT", 2
        ]

    def _parse_search_results(self, results: List, apply_threshold: bool = True) -> Dict[str, Any]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ê³  ì„ê³„ê°’ì„ ì ìš©í•©ë‹ˆë‹¤."""
        response_data = {
            "is_cache": False,
            "similarity": 0.0,
            "data": {},
            "total_results": 0
        }

        if not results or results[0] == 0:
            logger.info("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return response_data

        response_data["total_results"] = results[0]
        logger.info(f"ğŸ“Š ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {results[0]}")

        # ëª¨ë“  ê²°ê³¼ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        logger.info("ğŸ” ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼:")
        for i in range(1, len(results), 2):
            if i + 1 < len(results):
                key = results[i]
                data = results[i + 1]
                # ê°„ë‹¨í•œ ë°ì´í„° íŒŒì‹±
                data_iter = iter(data)
                temp_dict = {}
                for k, v in zip(data_iter, data_iter):
                    temp_dict[k] = v

                distance = float(temp_dict.get('__question_vector_score', 2.0))
                question = temp_dict.get('question', '')[:30]
                logger.info(f"   ê²°ê³¼ {(i + 1) // 2}: ê±°ë¦¬={distance:.6f}, ì§ˆë¬¸='{question}...'")

        # ì²« ë²ˆì§¸ ê²°ê³¼ ì²˜ë¦¬ (ì •ë ¬ í›„ ê°€ì¥ ìœ ì‚¬í•œ ê²°ê³¼)
        if len(results) >= 3:
            try:
                key = results[1]
                data = results[2]

                # ê²°ê³¼ ë°ì´í„° íŒŒì‹±
                data_iter = iter(data)
                result_dict = {}
                for k, v in zip(data_iter, data_iter):
                    result_dict[k] = v

                # ìœ ì‚¬ë„ ê³„ì‚°
                distance = float(result_dict.get('__question_vector_score', 2.0))

                # COSINE ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                # ê±°ë¦¬: 0(ì™„ì „ ë™ì¼) ~ 2(ì™„ì „ ë‹¤ë¦„)
                # ìœ ì‚¬ë„: 1(ì™„ì „ ë™ì¼) ~ 0(ì™„ì „ ë‹¤ë¦„)
                if distance <= 2.0:
                    similarity = max(0.0, 1.0 - (distance / 2.0))
                else:
                    similarity = 0.0

                response_data["similarity"] = round(similarity, 4)

                logger.info(f"ğŸ¯ ìµœì  ê²°ê³¼ - ê±°ë¦¬ê°’: {distance:.6f} â†’ ìœ ì‚¬ë„: {similarity:.4f} ({similarity * 100:.1f}%)")
                logger.info(f"ğŸ“ ë§¤ì¹­ëœ ì§ˆë¬¸: '{result_dict.get('question', '')}'")

                # ì„ê³„ê°’ ì ìš©
                if apply_threshold and similarity >= self.similarity_threshold:
                    response_data["is_cache"] = True

                    # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
                    response_data["data"] = {
                        "id": key.replace(self.key_prefix, ''),
                        "question": result_dict.get('question', ''),
                        "response": result_dict.get('response', ''),
                        "created_at": int(result_dict.get('created_at', 0)),
                        "last_accessed": int(result_dict.get('last_accessed', 0)),
                        "hits": int(result_dict.get('hits', 0))
                    }

                    logger.info(f"âœ… ìºì‹œ íˆíŠ¸! ìœ ì‚¬ë„ {similarity:.4f} >= ì„ê³„ê°’ {self.similarity_threshold}")
                    logger.info(f"ğŸ“„ ë°˜í™˜í•  ë‹µë³€: '{result_dict.get('response', '')[:50]}...'")
                else:
                    logger.info(f"âŒ ìœ ì‚¬ë„ ì„ê³„ê°’ ë¯¸ë‹¬: {similarity:.4f} < {self.similarity_threshold}")
                    logger.info(f"ğŸ’¡ íŒíŠ¸: ì„ê³„ê°’ì„ {similarity:.2f} ì´í•˜ë¡œ ë‚®ì¶”ë©´ íˆíŠ¸ë©ë‹ˆë‹¤.")

            except Exception as e:
                logger.error(f"âŒ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)

        return response_data
    # --- ì£¼ìš” ê²€ìƒ‰ ë° ìºì‹± ë©”ì„œë“œ ---

    def search_similar_question(self, question_vector, limit: int = 5) -> Dict[str, Any]:
        """
        ìœ ì‚¬í•œ ì§ˆë¬¸ì„ ê²€ìƒ‰í•˜ê³  ìºì‹œ íˆíŠ¸ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            question_vector: ì§ˆë¬¸ì˜ ì„ë² ë”© ë²¡í„°
            limit: ê²€ìƒ‰í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            Dict: ê²€ìƒ‰ ê²°ê³¼ ë° ìºì‹œ íˆíŠ¸ ì •ë³´
        """
        start_time = time.time()

        try:
            # ë²¡í„° ë³€í™˜
            vector_bytes = self._prepare_vector_bytes(question_vector)
            if not vector_bytes:
                logger.error("ë²¡í„° ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return {"is_cache": False, "similarity": 0.0, "data": {}, "total_results": 0}

            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„± ë° ì‹¤í–‰
            query_args = self._build_vector_search_query(vector_bytes, limit)
            redis_conn_raw = self._get_raw_redis_connection()

            logger.info(f"ë²¡í„° ê²€ìƒ‰ ì‹œì‘: limit={limit}")
            results = redis_conn_raw.execute_command(*query_args)
            logger.info(f"ê²°ê³¼: limit={results}")
            # ê²°ê³¼ íŒŒì‹±
            parsed_result = self._parse_search_results(results)

            # ìºì‹œ íˆíŠ¸ ì‹œ ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸
            if parsed_result["is_cache"] and parsed_result["data"]:
                self._update_access_record(parsed_result["data"]["id"])
            elapsed_time = time.time() - start_time
            logger.info(f"ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {elapsed_time:.3f}ì´ˆ")

            return parsed_result

        except RedisError as e:
            logger.error(f"[ë²¡í„° ê²€ìƒ‰] Redis ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return {"is_cache": False, "similarity": 0.0, "data": {}, "total_results": 0}
        except Exception as e:
            logger.error(f"[ë²¡í„° ê²€ìƒ‰] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"is_cache": False, "similarity": 0.0, "data": {}, "total_results": 0}

    def _update_access_record(self, entry_id: str) -> bool:
        """ì ‘ê·¼ ê¸°ë¡ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤ (hits ì¦ê°€, last_accessed ê°±ì‹ )."""
        try:
            redis_conn = self._get_redis_connection()
            key = f"{self.key_prefix}{entry_id}"

            if not redis_conn.exists(key):
                logger.warning(f"[ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸] í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: id={entry_id}")
                return False

            # í˜„ì¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            current_data = redis_conn.hmget(key, ['hits', 'last_accessed'])

            current_hits = int(current_data[0] if current_data[0] else 0)
            current_time = int(time.time())

            # ë³€ê²½ ì „ (Deprecated):
            # redis_conn.hmset(key, {
            #     'hits': current_hits + 1,
            #     'last_accessed': current_time
            # })

            # ë³€ê²½ í›„ (ê¶Œì¥):
            redis_conn.hset(key, mapping={
                'hits': current_hits + 1,
                'last_accessed': current_time
            })

            logger.info(f"[ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸] ì™„ë£Œ: id={entry_id}, hits={current_hits + 1}")
            return True

        except Exception as e:
            logger.error(f"[ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸] ì˜¤ë¥˜: {e}")
            return False

    def store_question_response(self, question: str, response: str, question_vector) -> Optional[str]:
        """ì§ˆë¬¸ê³¼ ì‘ë‹µ ìŒì„ Redisì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            # ê³ ìœ  ID ìƒì„±
            timestamp = int(time.time())
            entry_id = f"{timestamp}_{hash(question) % 10000}"
            key = f"{self.key_prefix}{entry_id}"

            # ë²¡í„° ë³€í™˜
            vector_bytes = self._prepare_vector_bytes(question_vector)
            if not vector_bytes:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ë²¡í„°ë¡œ ë³€í™˜ ë¶ˆê°€")

            # ë‚ ì§œ ë¬¸ìì—´ ìƒì„± (YYYYMMDD)
            date_str = datetime.now().strftime("%Y%m%d")

            # ë°ì´í„° êµ¬ì„± (ìë™ ì¸ì½”ë”©ì„ ìœ„í•´ ë¬¸ìì—´ë¡œ ì €ì¥)
            data_fields = {
                'question': question,
                'response': response,
                'created_at': str(timestamp),
                'last_accessed': str(timestamp),
                'hits': '0',
                'date_str': date_str
            }

            # Redisì— ì €ì¥
            redis_conn = self._get_redis_connection()
            redis_conn_raw = self._get_raw_redis_connection()

            # íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
            pipe = redis_conn.pipeline()

            # í…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” ìë™ ì¸ì½”ë”© ì—°ê²°ë¡œ ì €ì¥
            pipe.hset(key, mapping=data_fields)
            pipe.execute()

            # ë²¡í„° ë°ì´í„°ëŠ” raw ì—°ê²°ë¡œ ì €ì¥
            redis_conn_raw.hset(key, 'question_vector', vector_bytes)

            logger.info(f"[ì €ì¥] í•­ëª© ì €ì¥ ì™„ë£Œ: id={entry_id}")
            return entry_id

        except (RedisError, ValueError) as e:
            logger.error(f"[ì €ì¥] í•­ëª© ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return None

    def get_entry_by_id(self, entry_id: str, update_access: bool = True) -> Optional[Dict[str, Any]]:
        """IDë¡œ íŠ¹ì • í•­ëª©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            redis_conn = self._get_redis_connection()
            key = f"{self.key_prefix}{entry_id}"

            if not redis_conn.exists(key):
                logger.warning(f"[í•­ëª© ì¡°íšŒ] í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: id={entry_id}")
                return None

            # ëª¨ë“  í•„ë“œ ê°€ì ¸ì˜¤ê¸°
            data = redis_conn.hgetall(key)
            if not data:
                return None

            # ê²°ê³¼ êµ¬ì„±
            entry_data = {
                "id": entry_id,
                "question": data.get('question', ''),
                "response": data.get('response', ''),
                "created_at": int(data.get('created_at', 0)),
                "last_accessed": int(data.get('last_accessed', 0)),
                "hits": int(data.get('hits', 0)),
                "date_str": data.get('date_str', '')
            }

            # ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸
            if update_access:
                current_time = int(time.time())
                new_hits = entry_data['hits'] + 1

                redis_conn.hset(key, mapping={
                    'hits': new_hits,
                    'last_accessed': current_time
                })

                entry_data['hits'] = new_hits
                entry_data['last_accessed'] = current_time

            logger.info(f"[í•­ëª© ì¡°íšŒ] ì™„ë£Œ: id={entry_id}, hits={entry_data['hits']}")
            return entry_data

        except Exception as e:
            logger.error(f"[í•­ëª© ì¡°íšŒ] ID {entry_id} ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return None

    def get_redis_json_key(self,key: str):
        try:
            redis_conn = self._get_redis_connection()
            raw = redis_conn.get(key)
            if raw:
                return json.loads(raw)
            else:
                logger.error(f"âš ï¸ Redisì—ì„œ í‚¤ '{key}'ì˜ ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
        except Exception as e:
            logger.error(f"âŒ Redisì—ì„œ í‚¤ '{key}' ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            redis_conn = self._get_redis_connection()

            # ì „ì²´ í•­ëª© ìˆ˜ ì¡°íšŒ
            results = redis_conn.execute_command(
                "FT.SEARCH", self.index_name, "*",
                "LIMIT", 0, 0  # ê°œìˆ˜ë§Œ í™•ì¸
            )

            total_count = results[0] if results else 0

            # ì¸ë±ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            try:
                index_info = redis_conn.execute_command("FT.INFO", self.index_name)
                index_size = dict(zip(index_info[::2], index_info[1::2]))
            except:
                index_size = {}

            return {
                "total_entries": total_count,
                "index_name": self.index_name,
                "vector_dimension": self.vector_dim,
                "similarity_threshold": self.similarity_threshold,
                "index_info": index_size
            }

        except Exception as e:
            logger.error(f"ìºì‹œ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def delete_entry(self, entry_id: str) -> bool:
        """IDë¡œ í•­ëª©ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
        try:
            redis_conn = self._get_redis_connection()
            key = f"{self.key_prefix}{entry_id}"

            result = redis_conn.delete(key)
            if result > 0:
                logger.info(f"[ì‚­ì œ] í•­ëª© ì‚­ì œ ì™„ë£Œ: id={entry_id}")
                return True
            else:
                logger.warning(f"[ì‚­ì œ] í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: id={entry_id}")
                return False

        except RedisError as e:
            logger.error(f"[ì‚­ì œ] ID {entry_id} ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return False


# EmbeddingService í´ë˜ìŠ¤ (ê¸°ì¡´ ì½”ë“œ ì°¸ì¡°)
class EmbeddingService:
    """ì„ë² ë”© ìƒì„± ì„œë¹„ìŠ¤ (ì‹±ê¸€í„´)"""
    _instance = None
    _model = None

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def __init__(self):
        if EmbeddingService._model is None:
            try:
                from sentence_transformers import SentenceTransformer
                logger.info("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
                model_name = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
                EmbeddingService._model = SentenceTransformer(model_name)
                logger.info(f"ì„ë² ë”© ëª¨ë¸ '{model_name}' ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")

    def get_embedding(self, text: str):
        """í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if not text or not isinstance(text, str):
                logger.warning("ì˜ëª»ëœ ì…ë ¥ í…ìŠ¤íŠ¸")
                return None

            embedding = EmbeddingService._model.encode(text)
            return embedding

        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise RuntimeError(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")


# í†µí•© ìºì‹œ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
class QuestionAnswerCacheService:
    """ì§ˆë¬¸-ë‹µë³€ ìºì‹œ ì„œë¹„ìŠ¤ í†µí•© í´ë˜ìŠ¤"""

    def __init__(self):
        self.redis_manager = EnhancedRedisManager.get_instance()
        self.embedding_service = EmbeddingService.get_instance()

    def search_cached_answer(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ìºì‹œëœ ë‹µë³€ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            # ì§ˆë¬¸ì˜ ì„ë² ë”© ìƒì„±
            question_embedding = self.embedding_service.get_embedding(question)
            if question_embedding is None:
                return {"is_cache": False, "error": "ì„ë² ë”© ìƒì„± ì‹¤íŒ¨"}

            # ìœ ì‚¬í•œ ì§ˆë¬¸ ê²€ìƒ‰
            result = self.redis_manager.search_similar_question(question_embedding)

            return result

        except Exception as e:
            logger.error(f"ìºì‹œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"is_cache": False, "error": str(e)}

    def cache_question_answer(self, question: str, answer: str) -> Optional[str]:
        """ì§ˆë¬¸-ë‹µë³€ ìŒì„ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            # ì§ˆë¬¸ì˜ ì„ë² ë”© ìƒì„±
            question_embedding = self.embedding_service.get_embedding(question)
            if question_embedding is None:
                logger.error("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return None

            # Redisì— ì €ì¥
            entry_id = self.redis_manager.store_question_response(
                question, answer, question_embedding
            )

            return entry_id

        except Exception as e:
            logger.error(f"ìºì‹œ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return None


# ì‚¬ìš© ì˜ˆì œ
def main():
    """ì‚¬ìš© ì˜ˆì œ"""
    try:
        # ìºì‹œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        cache_service = QuestionAnswerCacheService()

        # ì§ˆë¬¸-ë‹µë³€ ì €ì¥
        question = "Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€?"
        answer = "Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ë ¤ë©´ sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

        entry_id = cache_service.cache_question_answer(question, answer)
        print(f"ì €ì¥ëœ í•­ëª© ID: {entry_id}")

        # ìœ ì‚¬í•œ ì§ˆë¬¸ ê²€ìƒ‰
        similar_question = "íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ì •ë ¬ ë°©ë²•"
        result = cache_service.search_cached_answer(similar_question)

        print(f"ê²€ìƒ‰ ê²°ê³¼: {json.dumps(result, indent=2, ensure_ascii=False)}")

        # ìºì‹œ í†µê³„
        stats = cache_service.redis_manager.get_cache_stats()
        print(f"ìºì‹œ í†µê³„: {json.dumps(stats, indent=2, ensure_ascii=False)}")

        result = cache_service.search_cached_answer("Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€?")
        logger.debug("==   ê²€ìƒ‰ ê²°ê³¼ ==")
        logger.debug(result)
        logger.debug("==   ê²€ìƒ‰ ê²°ê³¼ ==")

    except Exception as e:
        logger.error(f"ì˜ˆì œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()